{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Entity Recognition (Proof of Concept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from model import init_llm\n",
    "from dotenv import load_dotenv\n",
    "from prompts import get_blurb_prompt, get_eval_with_feature_prompt\n",
    "import random\n",
    "import time \n",
    "import json\n",
    "\n",
    "verbose = False\n",
    "load_dotenv()\n",
    "file_path = 'dataset_100.jsonl'\n",
    "eval_file_path = 'eval.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to randomly select subsets of varying sizes\n",
    "def select_random_subsets(input_list, num_subsets):\n",
    "    subsets = []\n",
    "    list_length = len(input_list)\n",
    "    \n",
    "    for _ in range(num_subsets):\n",
    "        subset_size = random.randint(1, list_length)  # Random subset size\n",
    "        subset = random.sample(input_list, subset_size)\n",
    "        subsets.append(subset)\n",
    "    \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the language model\n",
    "llm = init_llm()\n",
    "\n",
    "prompt = get_blurb_prompt()\n",
    "\n",
    "gen_query_chain = langchain.LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=verbose\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-defined feature sets\n",
    "\n",
    "# features = ['price', 'phone_number', 'color', 'dimension']\n",
    "features = ['color', 'dimension', 'price', 'location']\n",
    "positive = ['color', 'dimension']\n",
    "negative = [\"price\", \"location\"]\n",
    "\n",
    "colors = [\"red\", \"blue\", \"green\", \"yellow\", \"black\", \"white\", \"purple\", \"orange\", \"pink\", \"brown\"]\n",
    "phone_numbers = [\"123-456-7890\", \"234-567-8901\", \"345-678-9012\", \"456-789-0123\", \"567-890-1234\", \"678-901-2345\", \"789-012-3456\", \"890-123-4567\", \"901-234-5678\", \"012-345-6789\"]\n",
    "prices = [\"$100\", \"$200\", \"$300\", \"$400\", \"$500\", \"$600\", \"$700\", \"$800\", \"$900\", \"$1000\"]\n",
    "dimensions = [\"1x1\", \"2x2\", \"3x3\", \"4x4\", \"5x5\", \"6x6\", \"7x7\", \"8x8\", \"9x9\", \"10x10\"]\n",
    "locations = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\", \"San Antonio\", \"San Diego\", \"Dallas\", \"San Jose\"]\n",
    "\n",
    "data = {'color': colors, 'location': locations, 'price': prices, 'dimension': dimensions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_subsets = select_random_subsets(features, 100)\n",
    "\n",
    "ground_truths = []\n",
    "\n",
    "for idx, feature_set in enumerate(random_subsets):\n",
    "\n",
    "    ground_truth_feature = []\n",
    "    ground_truth_value = []\n",
    "    negative_feature = []\n",
    "    negative_value = []\n",
    "    \n",
    "    vals = []\n",
    "    \n",
    "\n",
    "    for feature in feature_set:\n",
    "        if feature == \"dimension\":\n",
    "            dim = random.choice(data[feature])\n",
    "            ground_truth_value.append(dim)\n",
    "            ground_truth_feature.append(feature)\n",
    "            vals.append(dim)\n",
    "        \n",
    "        if feature == \"color\":\n",
    "            col = random.choice(data[feature])\n",
    "            ground_truth_value.append(col)\n",
    "            ground_truth_feature.append(feature)\n",
    "            vals.append(col)\n",
    "\n",
    "        if feature == \"price\":\n",
    "            pri = random.choice(data[feature])\n",
    "            negative_value.append(pri)\n",
    "            negative_feature.append(feature)\n",
    "            vals.append(pri)\n",
    "\n",
    "        if feature == \"phone_number\":\n",
    "            pho = random.choice(data[feature])\n",
    "            negative_value.append(pho)\n",
    "            negative_feature.append(feature)\n",
    "            vals.append(pho)\n",
    "            \n",
    "        if feature == \"location\":\n",
    "            loc = random.choice(data[feature])\n",
    "            negative_value.append(loc)\n",
    "            negative_feature.append(feature)\n",
    "            vals.append(loc)\n",
    "\n",
    "    output = gen_query_chain.predict(features=feature_set, values=vals)\n",
    "\n",
    "    temp = {\"Query\": output,\n",
    "            \"Feature Set\": feature_set, \n",
    "            \"Values\": vals, \n",
    "            \"Ground Truth Features\": ground_truth_feature, \n",
    "            \"Ground Truth Values\": ground_truth_value, \n",
    "            \"Negative Features\": negative_feature, \n",
    "            \"Negative Values\": negative_value}\n",
    "\n",
    "    with open(file_path, \"a\") as f:\n",
    "        json.dump(temp, f)  # Write JSON object\n",
    "        f.write('\\n')       # Add a newline to separate objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the language model\n",
    "llm = init_llm()\n",
    "\n",
    "prompt = get_eval_with_feature_prompt()\n",
    "\n",
    "eval_query_chain = langchain.LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=verbose\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        content = json.loads(line)\n",
    "        output = eval_query_chain.predict(features=positive, post=content['Query'])\n",
    "        with open(eval_file_path, \"a\") as f:\n",
    "            temp = {\"Response\": output}\n",
    "            json.dump(temp, f)  # Write JSON object\n",
    "            f.write('\\n')       # Add a newline to separate objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
